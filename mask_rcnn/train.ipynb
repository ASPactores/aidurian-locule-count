{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LoculesConfig(Config):\n",
    "    NAME = \"locules\"\n",
    "    BACKBONE = \"resnet50\"\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 2 + 1\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "    IMAGE_RESIZE_MODE = \"square\"\n",
    "    IMAGE_MIN_DIM = 640\n",
    "    IMAGE_MAX_DIM = 640\n",
    "    \n",
    "    LEARNING_RATE = 0.001\n",
    "    LEARNING_MOMENTUM = 0.9\n",
    "    WEIGHT_DECAY = 0.0001\n",
    "\n",
    "config = LoculesConfig()\n",
    "config.display()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.custom_dataset import DurianLoculeDataset\n",
    "\n",
    "dataset_train = DurianLoculeDataset()\n",
    "dataset_train.load_data('./dataset/dataset/locule-4/train/_annotations.coco.json', './dataset/dataset/locule-4/train/')\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_val = DurianLoculeDataset()\n",
    "dataset_val.load_data('./dataset/dataset/locule-4/valid/_annotations.coco.json', './dataset/dataset/locule-4/valid/')\n",
    "dataset_val.prepare()\n",
    "\n",
    "dataset = dataset_train\n",
    "image_ids = np.random.choice(dataset.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset.load_image(image_id)\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)\n",
    "    \n",
    "dataset = dataset_val\n",
    "image_ids = np.random.choice(dataset.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset.load_image(image_id)\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "print(COCO_MODEL_PATH)\n",
    "print(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)\n",
    "\n",
    "# Train from coco checkpoint\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=1, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test/visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the model in training or inference modes values: 'inference' or 'training'\n",
    "TEST_MODE = \"inference\"\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=16):\n",
    "  \"\"\"Return a Matplotlib Axes array to be used in all visualizations in the notebook.  Provide a central point to control graph sizes. Adjust the size attribute to control how big to render images\"\"\"\n",
    "  _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "  return ax\n",
    "\n",
    "# Load validation dataset\n",
    "# Must call before using the dataset\n",
    "CUSTOM_DIR = f\"{ROOT_DIR}/dataset/dataset/locule-4\"\n",
    "print(CUSTOM_DIR)\n",
    "dataset_test = DurianLoculeDataset()\n",
    "dataset_test.load_data('./dataset/dataset/locule-4/train/_annotations.coco.json', './dataset/dataset/locule-4/train/')\n",
    "dataset_test.prepare()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = LoculesConfig()\n",
    "# model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=\"./logs/locules20241028T2112/mask_rcnn_locules_0003.h5\")\n",
    "test_model = modellib.MaskRCNN(mode=\"inference\", config=test_config, model_dir=MODEL_DIR)\n",
    "\n",
    "WEIGHTS_PATH = \"./logs/locules20241028T2112/mask_rcnn_locules_0003.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading weights \", WEIGHTS_PATH)\n",
    "test_model.load_weights(WEIGHTS_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN DETECTION\n",
    "image_id = random.choice(dataset_test.image_ids)\n",
    "#image_id = 'D:/MaskRCNN-aar/Dataset/val/1.jfif'\n",
    "print(\"image id is :\",image_id)\n",
    "image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "modellib.load_image_gt(dataset_test, test_config, image_id)\n",
    "info = dataset_test.image_info[image_id]\n",
    "# print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id,dataset.image_reference(image_id)))\n",
    "\n",
    "# Run object detection\n",
    "results = test_model.detect([image], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "# # Display results\n",
    "# x = get_ax(1)\n",
    "# r = results[0]\n",
    "# ax = plt.gca()\n",
    "# visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], dataset_test.class_names, r['scores'], figAx=ax, title=\"Predictions\")\n",
    "# log(\"gt_class_id\", gt_class_id)\n",
    "# log(\"gt_bbox\", gt_bbox)\n",
    "# log(\"gt_mask\", gt_mask)\n",
    "\n",
    "# IMAGE=\"./dataset/dataset/locule-4/train/27-09-2023_DSLR_CLASS2-MIDRIPE_5D-13_05_03_JPG.rf.71de4574f5397e2cc69c038e51cc0774.jpg\"\n",
    "\n",
    "# # This is for predicting images which are not present in dataset\n",
    "# path_to_new_image = IMAGE # Change this\n",
    "# image1 = mpimg.imread(path_to_new_image)\n",
    "\n",
    "# # Run object detection\n",
    "# print(len([image1]))\n",
    "# results1 = model.detect([image1], verbose=1)\n",
    "\n",
    "# # Display results\n",
    "# ax = get_ax(1)\n",
    "# r1 = results1[0]\n",
    "# visualize.display_instances(image1, r1['rois'], r1['masks'], r1['class_ids'],\n",
    "# dataset_test.class_names, r1['scores'], figAx=ax, title=\"Predictions1\")\n",
    "\n",
    "# Display results\n",
    "x = get_ax(1)\n",
    "r = results[0]\n",
    "\n",
    "# Create figure and axis for passing as figAx\n",
    "fig, ax = plt.subplots(1)\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], dataset_test.class_names, r['scores'], figAx=(fig, ax), title=\"Predictions\")\n",
    "\n",
    "# Logging\n",
    "# log(\"gt_class_id\", gt_class_id)\n",
    "# log(\"gt_bbox\", gt_bbox)\n",
    "# log(\"gt_mask\", gt_mask)\n",
    "\n",
    "IMAGE = \"./dataset/dataset/locule-4/test/IMG_20240123_084847_jpg.rf.5fbf49557f5941f461eb188da4dae510.jpg\"\n",
    "\n",
    "# This is for predicting images not present in the dataset\n",
    "path_to_new_image = IMAGE  # Change this if needed\n",
    "image1 = mpimg.imread(path_to_new_image)\n",
    "\n",
    "# Run object detection\n",
    "print(len([image1]))\n",
    "results1 = test_model.detect([image1], verbose=1)\n",
    "\n",
    "# Display results for the new image\n",
    "fig, ax = plt.subplots(1)  # Create new figure and axis\n",
    "r1 = results1[0]\n",
    "visualize.display_instances(image1, r1['rois'], r1['masks'], r1['class_ids'],\n",
    "                            dataset_test.class_names, r1['scores'], figAx=(fig, ax), title=\"Predictions1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics:\n",
    "\n",
    "- mAP@0.5\n",
    "- mAP@0.75\n",
    "- mAP@0.5-0.95\n",
    "- mIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "mask_rcnn_pattern = r'^mask_rcnn.*\\.h5$'\n",
    "home_dir = os.getcwd()\n",
    "\n",
    "# Get the first item in the MODEL_DIR\n",
    "latest_log_dir = os.listdir(MODEL_DIR)[1]  # Change to 0\n",
    "directory_content = os.listdir(os.path.join(MODEL_DIR, latest_log_dir))\n",
    "\n",
    "# Search for files matching the mask_rcnn pattern\n",
    "matching_files = [f for f in directory_content if re.search(mask_rcnn_pattern, f)]\n",
    "\n",
    "# Check if there are any matching files\n",
    "if matching_files:\n",
    "    latest_weight = matching_files[-1]\n",
    "    print(\"Latest matching file:\", latest_weight)\n",
    "\n",
    "    # Construct the full path to the latest weight file\n",
    "    latest_weight_dir = os.path.join(MODEL_DIR, latest_log_dir, latest_weight)\n",
    "    print(\"Latest weight file path:\", latest_weight_dir)\n",
    "else:\n",
    "    print(\"No matching files found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.utils import compute_ap, compute_ap_range\n",
    "\n",
    "TEST_DATASET_JSON = \"./dataset/dataset/locule-4/test/_annotations.coco.json\"\n",
    "TEST_DATASET_DIR = \"./dataset/dataset/locule-4/test/\"\n",
    "TRAINED_MODEL_WEIGHTS_PATH = latest_weight_dir\n",
    "\n",
    "dataset_test = DurianLoculeDataset()\n",
    "dataset_test.load_data(TEST_DATASET_JSON, TEST_DATASET_DIR)\n",
    "dataset_test.prepare()\n",
    "\n",
    "test_config = LoculesConfig()\n",
    "test_model = modellib.MaskRCNN(mode=\"inference\", config=test_config, model_dir=MODEL_DIR)\n",
    "test_model.load_weights(TRAINED_MODEL_WEIGHTS_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_batch_ap(image_ids, iou_threshold=0.50):\n",
    "    APs = []\n",
    "    for image_id in image_ids:\n",
    "        # Load image\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset_test, test_config, image_id)\n",
    "        # Run object detection\n",
    "        results = test_model.detect([image], verbose=0)\n",
    "        # Compute AP\n",
    "        r = results[0]\n",
    "        AP, precisions, recalls, overlaps =\\\n",
    "            utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                            r['rois'], r['class_ids'], r['scores'], r['masks'], iou_threshold=iou_threshold)\n",
    "        APs.append(AP)\n",
    "    return APs\n",
    "\n",
    "image_ids = dataset_test.image_ids\n",
    "APs = compute_batch_ap(image_ids, iou_threshold=0.50)\n",
    "print(\"mAP @ IoU=50: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_batch_ranged_ap(image_ids):\n",
    "    APs = []\n",
    "    for image_id in image_ids:\n",
    "        # Load image\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset_test, test_config, image_id)\n",
    "        \n",
    "        # Run object detection\n",
    "        results = test_model.detect([image], verbose=0)\n",
    "        r = results[0]\n",
    "        \n",
    "        # Compute AP (assuming compute_ap_range only returns AP as a single float)\n",
    "        AP = utils.compute_ap_range(\n",
    "            gt_bbox, gt_class_id, gt_mask,\n",
    "            r['rois'], r['class_ids'], r['scores'], r['masks'], verbose=0\n",
    "        )\n",
    "        \n",
    "        # Append AP score for this image to the list\n",
    "        APs.append(AP)\n",
    "    \n",
    "    return APs\n",
    "\n",
    "# Get list of image IDs and compute ranged APs\n",
    "image_ids = dataset_test.image_ids\n",
    "APs = compute_batch_ranged_ap(image_ids)\n",
    "\n",
    "# Print mean AP\n",
    "print(\"mAP: \", np.mean(APs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.utils import get_iou\n",
    "\n",
    "def draw_bounding_boxes(ax, image, gt_box, best_pred_box, image_id):\n",
    "    \"\"\"\n",
    "    Draw ground truth and predicted bounding boxes on the given axes.\n",
    "    \n",
    "    Args:\n",
    "        ax: The axes to draw on.\n",
    "        image: The image to display.\n",
    "        gt_box: The ground truth bounding box in the format [y0, x1, y2, x2].\n",
    "        best_pred_box: The best predicted bounding box in the format [y0, x1, y2, x2].\n",
    "        image_id: The ID of the image.\n",
    "    \"\"\"\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    # Draw ground truth box\n",
    "    gt_y0, gt_x1, gt_y2, gt_x2 = gt_box\n",
    "    ax.add_patch(plt.Rectangle((gt_x1, gt_y0), gt_x2 - gt_x1, gt_y2 - gt_y0,\n",
    "                                fill=False, edgecolor='red', lw=2, label='Ground Truth'))\n",
    "    \n",
    "    # Draw predicted box if it exists\n",
    "    if best_pred_box is not None:\n",
    "        pred_y0, pred_x1, pred_y2, pred_x2 = best_pred_box\n",
    "        ax.add_patch(plt.Rectangle((pred_x1, pred_y0), pred_x2 - pred_x1, pred_y2 - pred_y0,\n",
    "                                    fill=False, edgecolor='blue', lw=2, label='Prediction'))\n",
    "\n",
    "    ax.set_title(f\"Image ID: {image_id}\")\n",
    "\n",
    "def display_bounding_boxes(image_data):\n",
    "    \"\"\"\n",
    "    Display images with their ground truth and predicted bounding boxes in a grid layout.\n",
    "\n",
    "    Args:\n",
    "        image_data: A dictionary where keys are image IDs and values are lists of tuples \n",
    "                    containing (image, gt_box, best_pred_box).\n",
    "    \"\"\"\n",
    "    max_columns = 6  # Maximum number of columns\n",
    "    rows = len(image_data)  # Number of unique image IDs\n",
    "    grid_size = (rows, max_columns)  # Grid size (rows, columns)\n",
    "    \n",
    "    fig, axes = plt.subplots(*grid_size, figsize=(15, 5 * rows))\n",
    "    axes = axes.flatten()  # Flatten the grid for easy iteration\n",
    "\n",
    "    for idx, (image_id, bounding_boxes) in enumerate(image_data.items()):\n",
    "        for col in range(max_columns):\n",
    "            ax = axes[idx * max_columns + col]\n",
    "            if col < len(bounding_boxes):\n",
    "                image, gt_box, best_pred_box = bounding_boxes[col]\n",
    "                draw_bounding_boxes(ax, image, gt_box, best_pred_box, image_id)\n",
    "            else:\n",
    "                ax.axis('off')  # Hide axes if no image available\n",
    "\n",
    "    plt.tight_layout(pad=0.5, h_pad=0.5)  # Adjust layout\n",
    "    plt.show()\n",
    "\n",
    "def compute_batch_iou(image_ids):\n",
    "    IOUs = []\n",
    "    image_data = {}\n",
    "    selected_image_ids = np.random.choice(image_ids, 2)  # Select 2 random image IDs\n",
    "\n",
    "    for image_id in image_ids:\n",
    "        # Load image\n",
    "        image, _, _, gt_bbox, _ = modellib.load_image_gt(dataset_test, test_config, image_id)\n",
    "        \n",
    "        # Run object detection\n",
    "        results = test_model.detect([image], verbose=0)\n",
    "        r = results[-1]\n",
    "        \n",
    "        # Prepare to store bounding boxes for this image_id\n",
    "        bounding_boxes = []\n",
    "\n",
    "        # Loop over each ground truth bounding box\n",
    "        for gt_box in gt_bbox:\n",
    "            gt_y0, gt_x1, gt_y2, gt_x2 = gt_box\n",
    "            best_iou = -1\n",
    "            best_pred_box = None\n",
    "            \n",
    "            # Find the predicted box with the highest IoU for this ground truth box\n",
    "            for pred_box in r['rois']:\n",
    "                pred_y0, pred_x1, pred_y2, pred_x2 = pred_box\n",
    "                iou = get_iou([gt_x1, gt_y0, gt_x2, gt_y2], [pred_x1, pred_y0, pred_x2, pred_y2])\n",
    "                \n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_pred_box = pred_box\n",
    "            \n",
    "            IOUs.append(best_iou)\n",
    "            bounding_boxes.append((image, gt_box, best_pred_box))\n",
    "        \n",
    "        # Store the bounding boxes for the current image_id if it's selected\n",
    "        if image_id in selected_image_ids:\n",
    "            image_data.setdefault(image_id, []).extend(bounding_boxes)\n",
    "\n",
    "    # Display all images in a grid\n",
    "    display_bounding_boxes(image_data)\n",
    "    \n",
    "    return IOUs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get list of image IDs and compute IoUs\n",
    "image_ids = dataset_test.image_ids\n",
    "IOUs = compute_batch_iou(image_ids)\n",
    "print(\"Mean IoU: \", np.mean(IOUs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.9078176347498905"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
